{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3bbb7de9",
   "metadata": {},
   "source": [
    "# 📘 Hands-on Guide to Fine-Tuning Mi:dm 2.0 using TRL\n",
    "\n",
    "## 📑 Table of Contents\n",
    "\n",
    "1. [Introduction](#-introduction)  \n",
    "2. [Setup Environment](#-setup-environment)  \n",
    "3. [Prepare and Load the Dataset](#-prepare-and-load-the-dataset)  \n",
    "4. [Modeling with PEFT (LoRA)](#-modeling-with-peft-lora)  \n",
    "5. [Training the Model](#-training-the-model)  \n",
    "6. [Full Fine-Tuning (Optional)](#-full-fine-tuning-optional)\n",
    "\n",
    "---\n",
    "\n",
    "## 🧭 Introduction\n",
    "\n",
    "This is the guide code that allows you to finetune our publicly available Mi:dm 2.0 with new downstream tasks.  \n",
    "Mi:dm 2.0 can be used for a variety of tasks such as question answering and summarization, etc. without any additional training.  \n",
    "However, if you want to customise the model for your application, you may need to fine-tune it to your data to get better results.  \n",
    "Please modify it according to the availability of your resources.\n",
    "\n",
    "This tutorial notebook walks you thorugh how to fine-tune Mi:dm 2.0 using Hugging Face [TRL](https://huggingface.co/docs/trl/index), [Transformers](https://huggingface.co/docs/transformers/index) & [datasets](https://huggingface.co/docs/datasets/index). In the Notebook, we are going to:\n",
    "\n",
    "1. Setup environment  \n",
    "2. Prepare and load the dataset  \n",
    "3. Fine-tune LLM using `trl` and the `SFTTrainer`\n",
    "\n",
    "---\n",
    "\n",
    "## 🧰 Setup Environment\n",
    "\n",
    "Our first step is to install Hugging Face Libraries and Pytorch, including trl, transformers and datasets.  \n",
    "TRL is a cutting-edge library designed for post-training foundation models using advanced techniques like Supervised Fine-Tuning (SFT), Proximal Policy Optimization (PPO), and Direct Preference Optimization (DPO).\n",
    "\n",
    "> ⚠️ **Note:** Installing Flash Attention may take a while (approximately 10–45 minutes), depending on your system performance.  \n",
    "> It's an optional optimization that can significantly speed up attention computations during training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5ae3eaf4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting torch>=2.0.0 (from -r requirements.txt (line 1))\n",
      "  Using cached torch-2.7.1-cp310-cp310-manylinux_2_28_x86_64.whl.metadata (29 kB)\n",
      "Collecting accelerate>=1.4.0 (from -r requirements.txt (line 2))\n",
      "  Using cached accelerate-1.8.1-py3-none-any.whl.metadata (19 kB)\n",
      "Collecting datasets>=3.0.0 (from -r requirements.txt (line 3))\n",
      "  Using cached datasets-3.6.0-py3-none-any.whl.metadata (19 kB)\n",
      "Requirement already satisfied: transformers>=4.51.0 in /home/nlpgpu10/miniconda3/envs/midm2.0/lib/python3.10/site-packages (from -r requirements.txt (line 4)) (4.52.1)\n",
      "Collecting bitsandbytes>=0.43.2 (from -r requirements.txt (line 5))\n",
      "  Using cached bitsandbytes-0.46.1-py3-none-manylinux_2_24_x86_64.whl.metadata (10 kB)\n",
      "Collecting tensorboardX (from -r requirements.txt (line 6))\n",
      "  Using cached tensorboardx-2.6.4-py3-none-any.whl.metadata (6.2 kB)\n",
      "Collecting ninja (from -r requirements.txt (line 7))\n",
      "  Downloading ninja-1.11.1.4-py3-none-manylinux_2_12_x86_64.manylinux2010_x86_64.whl.metadata (5.0 kB)\n",
      "Requirement already satisfied: packaging in /home/nlpgpu10/miniconda3/envs/midm2.0/lib/python3.10/site-packages (from -r requirements.txt (line 8)) (25.0)\n",
      "Requirement already satisfied: filelock in /home/nlpgpu10/miniconda3/envs/midm2.0/lib/python3.10/site-packages (from torch>=2.0.0->-r requirements.txt (line 1)) (3.18.0)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in /home/nlpgpu10/miniconda3/envs/midm2.0/lib/python3.10/site-packages (from torch>=2.0.0->-r requirements.txt (line 1)) (4.14.0)\n",
      "Collecting sympy>=1.13.3 (from torch>=2.0.0->-r requirements.txt (line 1))\n",
      "  Downloading sympy-1.14.0-py3-none-any.whl.metadata (12 kB)\n",
      "Collecting networkx (from torch>=2.0.0->-r requirements.txt (line 1))\n",
      "  Downloading networkx-3.4.2-py3-none-any.whl.metadata (6.3 kB)\n",
      "Collecting jinja2 (from torch>=2.0.0->-r requirements.txt (line 1))\n",
      "  Downloading jinja2-3.1.6-py3-none-any.whl.metadata (2.9 kB)\n",
      "Requirement already satisfied: fsspec in /home/nlpgpu10/miniconda3/envs/midm2.0/lib/python3.10/site-packages (from torch>=2.0.0->-r requirements.txt (line 1)) (2025.5.1)\n",
      "Collecting nvidia-cuda-nvrtc-cu12==12.6.77 (from torch>=2.0.0->-r requirements.txt (line 1))\n",
      "  Downloading nvidia_cuda_nvrtc_cu12-12.6.77-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cuda-runtime-cu12==12.6.77 (from torch>=2.0.0->-r requirements.txt (line 1))\n",
      "  Downloading nvidia_cuda_runtime_cu12-12.6.77-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cuda-cupti-cu12==12.6.80 (from torch>=2.0.0->-r requirements.txt (line 1))\n",
      "  Downloading nvidia_cuda_cupti_cu12-12.6.80-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cudnn-cu12==9.5.1.17 (from torch>=2.0.0->-r requirements.txt (line 1))\n",
      "  Downloading nvidia_cudnn_cu12-9.5.1.17-py3-none-manylinux_2_28_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cublas-cu12==12.6.4.1 (from torch>=2.0.0->-r requirements.txt (line 1))\n",
      "  Downloading nvidia_cublas_cu12-12.6.4.1-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cufft-cu12==11.3.0.4 (from torch>=2.0.0->-r requirements.txt (line 1))\n",
      "  Downloading nvidia_cufft_cu12-11.3.0.4-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-curand-cu12==10.3.7.77 (from torch>=2.0.0->-r requirements.txt (line 1))\n",
      "  Downloading nvidia_curand_cu12-10.3.7.77-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cusolver-cu12==11.7.1.2 (from torch>=2.0.0->-r requirements.txt (line 1))\n",
      "  Downloading nvidia_cusolver_cu12-11.7.1.2-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cusparse-cu12==12.5.4.2 (from torch>=2.0.0->-r requirements.txt (line 1))\n",
      "  Downloading nvidia_cusparse_cu12-12.5.4.2-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cusparselt-cu12==0.6.3 (from torch>=2.0.0->-r requirements.txt (line 1))\n",
      "  Downloading nvidia_cusparselt_cu12-0.6.3-py3-none-manylinux2014_x86_64.whl.metadata (6.8 kB)\n",
      "Collecting nvidia-nccl-cu12==2.26.2 (from torch>=2.0.0->-r requirements.txt (line 1))\n",
      "  Downloading nvidia_nccl_cu12-2.26.2-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (2.0 kB)\n",
      "Collecting nvidia-nvtx-cu12==12.6.77 (from torch>=2.0.0->-r requirements.txt (line 1))\n",
      "  Downloading nvidia_nvtx_cu12-12.6.77-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-nvjitlink-cu12==12.6.85 (from torch>=2.0.0->-r requirements.txt (line 1))\n",
      "  Downloading nvidia_nvjitlink_cu12-12.6.85-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cufile-cu12==1.11.1.6 (from torch>=2.0.0->-r requirements.txt (line 1))\n",
      "  Downloading nvidia_cufile_cu12-1.11.1.6-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting triton==3.3.1 (from torch>=2.0.0->-r requirements.txt (line 1))\n",
      "  Downloading triton-3.3.1-cp310-cp310-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (1.5 kB)\n",
      "Requirement already satisfied: setuptools>=40.8.0 in /home/nlpgpu10/miniconda3/envs/midm2.0/lib/python3.10/site-packages (from triton==3.3.1->torch>=2.0.0->-r requirements.txt (line 1)) (78.1.1)\n",
      "Requirement already satisfied: numpy<3.0.0,>=1.17 in /home/nlpgpu10/miniconda3/envs/midm2.0/lib/python3.10/site-packages (from accelerate>=1.4.0->-r requirements.txt (line 2)) (2.2.6)\n",
      "Requirement already satisfied: psutil in /home/nlpgpu10/miniconda3/envs/midm2.0/lib/python3.10/site-packages (from accelerate>=1.4.0->-r requirements.txt (line 2)) (7.0.0)\n",
      "Requirement already satisfied: pyyaml in /home/nlpgpu10/miniconda3/envs/midm2.0/lib/python3.10/site-packages (from accelerate>=1.4.0->-r requirements.txt (line 2)) (6.0.2)\n",
      "Requirement already satisfied: huggingface_hub>=0.21.0 in /home/nlpgpu10/miniconda3/envs/midm2.0/lib/python3.10/site-packages (from accelerate>=1.4.0->-r requirements.txt (line 2)) (0.33.2)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /home/nlpgpu10/miniconda3/envs/midm2.0/lib/python3.10/site-packages (from accelerate>=1.4.0->-r requirements.txt (line 2)) (0.5.3)\n",
      "Collecting pyarrow>=15.0.0 (from datasets>=3.0.0->-r requirements.txt (line 3))\n",
      "  Downloading pyarrow-20.0.0-cp310-cp310-manylinux_2_28_x86_64.whl.metadata (3.3 kB)\n",
      "Collecting dill<0.3.9,>=0.3.0 (from datasets>=3.0.0->-r requirements.txt (line 3))\n",
      "  Using cached dill-0.3.8-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting pandas (from datasets>=3.0.0->-r requirements.txt (line 3))\n",
      "  Downloading pandas-2.3.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (91 kB)\n",
      "Requirement already satisfied: requests>=2.32.2 in /home/nlpgpu10/miniconda3/envs/midm2.0/lib/python3.10/site-packages (from datasets>=3.0.0->-r requirements.txt (line 3)) (2.32.4)\n",
      "Requirement already satisfied: tqdm>=4.66.3 in /home/nlpgpu10/miniconda3/envs/midm2.0/lib/python3.10/site-packages (from datasets>=3.0.0->-r requirements.txt (line 3)) (4.67.1)\n",
      "Collecting xxhash (from datasets>=3.0.0->-r requirements.txt (line 3))\n",
      "  Using cached xxhash-3.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
      "Collecting multiprocess<0.70.17 (from datasets>=3.0.0->-r requirements.txt (line 3))\n",
      "  Using cached multiprocess-0.70.16-py310-none-any.whl.metadata (7.2 kB)\n",
      "Collecting fsspec (from torch>=2.0.0->-r requirements.txt (line 1))\n",
      "  Downloading fsspec-2025.3.0-py3-none-any.whl.metadata (11 kB)\n",
      "Collecting aiohttp!=4.0.0a0,!=4.0.0a1 (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=3.0.0->-r requirements.txt (line 3))\n",
      "  Downloading aiohttp-3.12.13-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.6 kB)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /home/nlpgpu10/miniconda3/envs/midm2.0/lib/python3.10/site-packages (from transformers>=4.51.0->-r requirements.txt (line 4)) (2024.11.6)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in /home/nlpgpu10/miniconda3/envs/midm2.0/lib/python3.10/site-packages (from transformers>=4.51.0->-r requirements.txt (line 4)) (0.21.2)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /home/nlpgpu10/miniconda3/envs/midm2.0/lib/python3.10/site-packages (from huggingface_hub>=0.21.0->accelerate>=1.4.0->-r requirements.txt (line 2)) (1.1.5)\n",
      "Collecting protobuf>=3.20 (from tensorboardX->-r requirements.txt (line 6))\n",
      "  Downloading protobuf-6.31.1-cp39-abi3-manylinux2014_x86_64.whl.metadata (593 bytes)\n",
      "Collecting aiohappyeyeballs>=2.5.0 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=3.0.0->-r requirements.txt (line 3))\n",
      "  Downloading aiohappyeyeballs-2.6.1-py3-none-any.whl.metadata (5.9 kB)\n",
      "Collecting aiosignal>=1.1.2 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=3.0.0->-r requirements.txt (line 3))\n",
      "  Downloading aiosignal-1.4.0-py3-none-any.whl.metadata (3.7 kB)\n",
      "Collecting async-timeout<6.0,>=4.0 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=3.0.0->-r requirements.txt (line 3))\n",
      "  Downloading async_timeout-5.0.1-py3-none-any.whl.metadata (5.1 kB)\n",
      "Collecting attrs>=17.3.0 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=3.0.0->-r requirements.txt (line 3))\n",
      "  Downloading attrs-25.3.0-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting frozenlist>=1.1.1 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=3.0.0->-r requirements.txt (line 3))\n",
      "  Downloading frozenlist-1.7.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (18 kB)\n",
      "Collecting multidict<7.0,>=4.5 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=3.0.0->-r requirements.txt (line 3))\n",
      "  Downloading multidict-6.6.3-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (5.3 kB)\n",
      "Collecting propcache>=0.2.0 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=3.0.0->-r requirements.txt (line 3))\n",
      "  Downloading propcache-0.3.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
      "Collecting yarl<2.0,>=1.17.0 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=3.0.0->-r requirements.txt (line 3))\n",
      "  Downloading yarl-1.20.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (73 kB)\n",
      "Requirement already satisfied: idna>=2.0 in /home/nlpgpu10/miniconda3/envs/midm2.0/lib/python3.10/site-packages (from yarl<2.0,>=1.17.0->aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=3.0.0->-r requirements.txt (line 3)) (3.10)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /home/nlpgpu10/miniconda3/envs/midm2.0/lib/python3.10/site-packages (from requests>=2.32.2->datasets>=3.0.0->-r requirements.txt (line 3)) (3.4.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/nlpgpu10/miniconda3/envs/midm2.0/lib/python3.10/site-packages (from requests>=2.32.2->datasets>=3.0.0->-r requirements.txt (line 3)) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/nlpgpu10/miniconda3/envs/midm2.0/lib/python3.10/site-packages (from requests>=2.32.2->datasets>=3.0.0->-r requirements.txt (line 3)) (2025.6.15)\n",
      "Collecting mpmath<1.4,>=1.1.0 (from sympy>=1.13.3->torch>=2.0.0->-r requirements.txt (line 1))\n",
      "  Downloading mpmath-1.3.0-py3-none-any.whl.metadata (8.6 kB)\n",
      "Collecting MarkupSafe>=2.0 (from jinja2->torch>=2.0.0->-r requirements.txt (line 1))\n",
      "  Downloading MarkupSafe-3.0.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.0 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /home/nlpgpu10/miniconda3/envs/midm2.0/lib/python3.10/site-packages (from pandas->datasets>=3.0.0->-r requirements.txt (line 3)) (2.9.0.post0)\n",
      "Collecting pytz>=2020.1 (from pandas->datasets>=3.0.0->-r requirements.txt (line 3))\n",
      "  Downloading pytz-2025.2-py2.py3-none-any.whl.metadata (22 kB)\n",
      "Collecting tzdata>=2022.7 (from pandas->datasets>=3.0.0->-r requirements.txt (line 3))\n",
      "  Downloading tzdata-2025.2-py2.py3-none-any.whl.metadata (1.4 kB)\n",
      "Requirement already satisfied: six>=1.5 in /home/nlpgpu10/miniconda3/envs/midm2.0/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas->datasets>=3.0.0->-r requirements.txt (line 3)) (1.17.0)\n",
      "Downloading torch-2.7.1-cp310-cp310-manylinux_2_28_x86_64.whl (821.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m821.2/821.2 MB\u001b[0m \u001b[31m27.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cublas_cu12-12.6.4.1-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (393.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m393.1/393.1 MB\u001b[0m \u001b[31m31.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.6.80-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (8.9 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.9/8.9 MB\u001b[0m \u001b[31m21.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.6.77-py3-none-manylinux2014_x86_64.whl (23.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.7/23.7 MB\u001b[0m \u001b[31m31.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.6.77-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (897 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m897.7/897.7 kB\u001b[0m \u001b[31m23.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cudnn_cu12-9.5.1.17-py3-none-manylinux_2_28_x86_64.whl (571.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m571.0/571.0 MB\u001b[0m \u001b[31m30.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cufft_cu12-11.3.0.4-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (200.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m200.2/200.2 MB\u001b[0m \u001b[31m32.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cufile_cu12-1.11.1.6-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (1.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m12.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_curand_cu12-10.3.7.77-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (56.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m30.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cusolver_cu12-11.7.1.2-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (158.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m158.2/158.2 MB\u001b[0m \u001b[31m31.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cusparse_cu12-12.5.4.2-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (216.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m216.6/216.6 MB\u001b[0m \u001b[31m32.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cusparselt_cu12-0.6.3-py3-none-manylinux2014_x86_64.whl (156.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m156.8/156.8 MB\u001b[0m \u001b[31m31.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_nccl_cu12-2.26.2-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (201.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m201.3/201.3 MB\u001b[0m \u001b[31m31.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.6.85-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl (19.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m19.7/19.7 MB\u001b[0m \u001b[31m26.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_nvtx_cu12-12.6.77-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (89 kB)\n",
      "Downloading triton-3.3.1-cp310-cp310-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (155.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m155.6/155.6 MB\u001b[0m \u001b[31m32.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading accelerate-1.8.1-py3-none-any.whl (365 kB)\n",
      "Downloading datasets-3.6.0-py3-none-any.whl (491 kB)\n",
      "Using cached dill-0.3.8-py3-none-any.whl (116 kB)\n",
      "Downloading fsspec-2025.3.0-py3-none-any.whl (193 kB)\n",
      "Using cached multiprocess-0.70.16-py310-none-any.whl (134 kB)\n",
      "Downloading bitsandbytes-0.46.1-py3-none-manylinux_2_24_x86_64.whl (72.9 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m72.9/72.9 MB\u001b[0m \u001b[31m30.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading tensorboardx-2.6.4-py3-none-any.whl (87 kB)\n",
      "Downloading ninja-1.11.1.4-py3-none-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (422 kB)\n",
      "Downloading aiohttp-3.12.13-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m10.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading async_timeout-5.0.1-py3-none-any.whl (6.2 kB)\n",
      "Downloading multidict-6.6.3-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (241 kB)\n",
      "Downloading yarl-1.20.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (326 kB)\n",
      "Downloading aiohappyeyeballs-2.6.1-py3-none-any.whl (15 kB)\n",
      "Downloading aiosignal-1.4.0-py3-none-any.whl (7.5 kB)\n",
      "Downloading attrs-25.3.0-py3-none-any.whl (63 kB)\n",
      "Downloading frozenlist-1.7.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (222 kB)\n",
      "Downloading propcache-0.3.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (198 kB)\n",
      "Downloading protobuf-6.31.1-cp39-abi3-manylinux2014_x86_64.whl (321 kB)\n",
      "Downloading pyarrow-20.0.0-cp310-cp310-manylinux_2_28_x86_64.whl (42.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.3/42.3 MB\u001b[0m \u001b[31m31.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading sympy-1.14.0-py3-none-any.whl (6.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.3/6.3 MB\u001b[0m \u001b[31m14.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading mpmath-1.3.0-py3-none-any.whl (536 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m536.2/536.2 kB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading jinja2-3.1.6-py3-none-any.whl (134 kB)\n",
      "Downloading MarkupSafe-3.0.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (20 kB)\n",
      "Downloading networkx-3.4.2-py3-none-any.whl (1.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m13.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading pandas-2.3.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (12.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.3/12.3 MB\u001b[0m \u001b[31m24.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading pytz-2025.2-py2.py3-none-any.whl (509 kB)\n",
      "Downloading tzdata-2025.2-py2.py3-none-any.whl (347 kB)\n",
      "Using cached xxhash-3.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n",
      "Installing collected packages: pytz, nvidia-cusparselt-cu12, mpmath, xxhash, tzdata, triton, sympy, pyarrow, protobuf, propcache, nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufile-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, ninja, networkx, multidict, MarkupSafe, fsspec, frozenlist, dill, attrs, async-timeout, aiohappyeyeballs, yarl, tensorboardX, pandas, nvidia-cusparse-cu12, nvidia-cufft-cu12, nvidia-cudnn-cu12, multiprocess, jinja2, aiosignal, nvidia-cusolver-cu12, aiohttp, torch, datasets, bitsandbytes, accelerate\n",
      "\u001b[2K  Attempting uninstall: fsspecm\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21/44\u001b[0m [multidict]las-cu12]u12]2]\n",
      "\u001b[2K    Found existing installation: fsspec 2025.5.1━━━━━━━━━━━━━━\u001b[0m \u001b[32m21/44\u001b[0m [multidict]\n",
      "\u001b[2K    Uninstalling fsspec-2025.5.1:\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21/44\u001b[0m [multidict]\n",
      "\u001b[2K      Successfully uninstalled fsspec-2025.5.1━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21/44\u001b[0m [multidict]\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44/44\u001b[0m [accelerate]celerate]tsandbytes]er-cu12]\n",
      "\u001b[1A\u001b[2KSuccessfully installed MarkupSafe-3.0.2 accelerate-1.8.1 aiohappyeyeballs-2.6.1 aiohttp-3.12.13 aiosignal-1.4.0 async-timeout-5.0.1 attrs-25.3.0 bitsandbytes-0.46.1 datasets-3.6.0 dill-0.3.8 frozenlist-1.7.0 fsspec-2025.3.0 jinja2-3.1.6 mpmath-1.3.0 multidict-6.6.3 multiprocess-0.70.16 networkx-3.4.2 ninja-1.11.1.4 nvidia-cublas-cu12-12.6.4.1 nvidia-cuda-cupti-cu12-12.6.80 nvidia-cuda-nvrtc-cu12-12.6.77 nvidia-cuda-runtime-cu12-12.6.77 nvidia-cudnn-cu12-9.5.1.17 nvidia-cufft-cu12-11.3.0.4 nvidia-cufile-cu12-1.11.1.6 nvidia-curand-cu12-10.3.7.77 nvidia-cusolver-cu12-11.7.1.2 nvidia-cusparse-cu12-12.5.4.2 nvidia-cusparselt-cu12-0.6.3 nvidia-nccl-cu12-2.26.2 nvidia-nvjitlink-cu12-12.6.85 nvidia-nvtx-cu12-12.6.77 pandas-2.3.0 propcache-0.3.2 protobuf-6.31.1 pyarrow-20.0.0 pytz-2025.2 sympy-1.14.0 tensorboardX-2.6.4 torch-2.7.1 triton-3.3.1 tzdata-2025.2 xxhash-3.5.0 yarl-1.20.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# Install Pytorch & other libraries\n",
    "%pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "12434adb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "assert torch.cuda.get_device_capability()[0] >= 8, 'Hardware not supported for Flash Attention'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cdb039d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting flash-attn==2.7.3\n",
      "  Using cached flash_attn-2.7.3.tar.gz (3.2 MB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: torch in /home/nlpgpu10/miniconda3/envs/midm2.0/lib/python3.10/site-packages (from flash-attn==2.7.3) (2.7.1)\n",
      "Collecting einops (from flash-attn==2.7.3)\n",
      "  Downloading einops-0.8.1-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: filelock in /home/nlpgpu10/miniconda3/envs/midm2.0/lib/python3.10/site-packages (from torch->flash-attn==2.7.3) (3.18.0)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in /home/nlpgpu10/miniconda3/envs/midm2.0/lib/python3.10/site-packages (from torch->flash-attn==2.7.3) (4.14.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in /home/nlpgpu10/miniconda3/envs/midm2.0/lib/python3.10/site-packages (from torch->flash-attn==2.7.3) (1.14.0)\n",
      "Requirement already satisfied: networkx in /home/nlpgpu10/miniconda3/envs/midm2.0/lib/python3.10/site-packages (from torch->flash-attn==2.7.3) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in /home/nlpgpu10/miniconda3/envs/midm2.0/lib/python3.10/site-packages (from torch->flash-attn==2.7.3) (3.1.6)\n",
      "Requirement already satisfied: fsspec in /home/nlpgpu10/miniconda3/envs/midm2.0/lib/python3.10/site-packages (from torch->flash-attn==2.7.3) (2025.3.0)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /home/nlpgpu10/miniconda3/envs/midm2.0/lib/python3.10/site-packages (from torch->flash-attn==2.7.3) (12.6.77)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /home/nlpgpu10/miniconda3/envs/midm2.0/lib/python3.10/site-packages (from torch->flash-attn==2.7.3) (12.6.77)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /home/nlpgpu10/miniconda3/envs/midm2.0/lib/python3.10/site-packages (from torch->flash-attn==2.7.3) (12.6.80)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.5.1.17 in /home/nlpgpu10/miniconda3/envs/midm2.0/lib/python3.10/site-packages (from torch->flash-attn==2.7.3) (9.5.1.17)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /home/nlpgpu10/miniconda3/envs/midm2.0/lib/python3.10/site-packages (from torch->flash-attn==2.7.3) (12.6.4.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /home/nlpgpu10/miniconda3/envs/midm2.0/lib/python3.10/site-packages (from torch->flash-attn==2.7.3) (11.3.0.4)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /home/nlpgpu10/miniconda3/envs/midm2.0/lib/python3.10/site-packages (from torch->flash-attn==2.7.3) (10.3.7.77)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /home/nlpgpu10/miniconda3/envs/midm2.0/lib/python3.10/site-packages (from torch->flash-attn==2.7.3) (11.7.1.2)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /home/nlpgpu10/miniconda3/envs/midm2.0/lib/python3.10/site-packages (from torch->flash-attn==2.7.3) (12.5.4.2)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.3 in /home/nlpgpu10/miniconda3/envs/midm2.0/lib/python3.10/site-packages (from torch->flash-attn==2.7.3) (0.6.3)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.26.2 in /home/nlpgpu10/miniconda3/envs/midm2.0/lib/python3.10/site-packages (from torch->flash-attn==2.7.3) (2.26.2)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /home/nlpgpu10/miniconda3/envs/midm2.0/lib/python3.10/site-packages (from torch->flash-attn==2.7.3) (12.6.77)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /home/nlpgpu10/miniconda3/envs/midm2.0/lib/python3.10/site-packages (from torch->flash-attn==2.7.3) (12.6.85)\n",
      "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /home/nlpgpu10/miniconda3/envs/midm2.0/lib/python3.10/site-packages (from torch->flash-attn==2.7.3) (1.11.1.6)\n",
      "Requirement already satisfied: triton==3.3.1 in /home/nlpgpu10/miniconda3/envs/midm2.0/lib/python3.10/site-packages (from torch->flash-attn==2.7.3) (3.3.1)\n",
      "Requirement already satisfied: setuptools>=40.8.0 in /home/nlpgpu10/miniconda3/envs/midm2.0/lib/python3.10/site-packages (from triton==3.3.1->torch->flash-attn==2.7.3) (78.1.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /home/nlpgpu10/miniconda3/envs/midm2.0/lib/python3.10/site-packages (from sympy>=1.13.3->torch->flash-attn==2.7.3) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/nlpgpu10/miniconda3/envs/midm2.0/lib/python3.10/site-packages (from jinja2->torch->flash-attn==2.7.3) (3.0.2)\n",
      "Downloading einops-0.8.1-py3-none-any.whl (64 kB)\n",
      "Building wheels for collected packages: flash-attn\n",
      "\u001b[33m  DEPRECATION: Building 'flash-attn' using the legacy setup.py bdist_wheel mechanism, which will be removed in a future version. pip 25.3 will enforce this behaviour change. A possible replacement is to use the standardized build interface by setting the `--use-pep517` option, (possibly combined with `--no-build-isolation`), or adding a `pyproject.toml` file to the source tree of 'flash-attn'. Discussion can be found at https://github.com/pypa/pip/issues/6334\u001b[0m\u001b[33m\n",
      "\u001b[0m  Building wheel for flash-attn (setup.py) ... \u001b[?25l|^C\n",
      "\u001b[?25canceled\n",
      "\u001b[31mERROR: Operation cancelled by user\u001b[0m\u001b[31m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!MAX_JOBS=4 pip install flash-attn==2.7.3 --no-build-isolation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8805597e",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 📂 Prepare and Load the Dataset\n",
    "\n",
    "In our example we’ll use an already existing dataset called [simpleQA-GenX2](https://huggingface.co/datasets/KT-AI/dataset), which contains samples of natural language instructions collected in-house, including various forms of simple Korean QA.\n",
    "\n",
    "With the latest release of `trl` we now support popular instruction and conversation dataset formats.\n",
    "\n",
    "### Supported Formats\n",
    "* conversational format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64554fb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "{\"messages\": [{\"role\": \"system\", \"content\": \"You are...\"}, {\"role\": \"user\", \"content\": \"...\"}, {\"role\": \"assistant\", \"content\": \"...\"}]}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03d45c9c",
   "metadata": {},
   "source": [
    "* instruction format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a9588a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "{\"prompt\": \"<prompt text>\", \"completion\": \"<ideal generated text>\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "676d49e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "# Load dataset from the hub\n",
    "dataset = load_dataset(\"K-intelligence/KT-Simple-QA\")['train']\n",
    "dataset = dataset.train_test_split(test_size=0.01)\n",
    "\n",
    "# save datasets to disk \n",
    "dataset[\"train\"].to_json(\"train_dataset.json\", orient=\"records\")\n",
    "dataset[\"test\"].to_json(\"test_dataset.json\", orient=\"records\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "119f6d3c",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 🧠 Modeling with PEFT (LoRA)\n",
    "\n",
    "### Load Mi:dm 2.0 Model and Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca9e7491",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig\n",
    "from trl import setup_chat_format\n",
    "\n",
    "model_id = \"K-intelligence/Midm-2.0-Mini-Instruct\"\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_id,\n",
    "    device_map=\"auto\",\n",
    "    attn_implementation=\"flash_attention_2\",\n",
    "    torch_dtype=torch.bfloat16\n",
    ")\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "930c9ad3",
   "metadata": {},
   "source": [
    "### Apply LoRA for PEFT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f800ecb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from peft import get_peft_model, LoraConfig, TaskType\n",
    "\n",
    "peft_config = LoraConfig(\n",
    "    r=8,\n",
    "    lora_alpha=16,\n",
    "    lora_dropout=0.1,\n",
    "    bias=\"none\",\n",
    "    task_type=TaskType.CAUSAL_LM,\n",
    ")\n",
    "model = get_peft_model(model, peft_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1e5edb2",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 🏋️ Training the Model\n",
    "\n",
    "### Load Dataset from Disk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fff4cc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "dataset = load_dataset(\"json\", data_files=\"train_dataset.json\", split=\"train\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cb6cd0c",
   "metadata": {},
   "source": [
    "### Set Training Arguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26f28098",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import TrainingArguments\n",
    "\n",
    "args = TrainingArguments(\n",
    "    output_dir=\"save_dir\",\n",
    "    num_train_epochs=1,\n",
    "    per_device_train_batch_size=1,\n",
    "    gradient_accumulation_steps=1,\n",
    "    gradient_checkpointing=True,\n",
    "    logging_steps=10,\n",
    "    save_strategy=\"epoch\",\n",
    "    learning_rate=2e-5,\n",
    "    bf16=True,\n",
    "    max_grad_norm=1.0,\n",
    "    warmup_ratio=0.03,\n",
    "    lr_scheduler_type=\"constant\",\n",
    "    push_to_hub=False,\n",
    "    report_to=\"tensorboard\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c024f102",
   "metadata": {},
   "source": [
    "### Set Up the `SFTTrainer` and Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c48d73a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from trl import SFTTrainer\n",
    "\n",
    "trainer = SFTTrainer(\n",
    "    model=model,\n",
    "    args=args,\n",
    "    train_dataset=dataset\n",
    ")\n",
    "\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "157cd478",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 🧬 Full Fine-Tuning (Optional)\n",
    "\n",
    "If you have enough computational resources and want to fine-tune the entire Mi:dm 2.0 model — not just adapters — you can follow the steps below.\n",
    "\n",
    "> ⚠️ **Note:** Dataset and library setup is the same as in the PEFT method above.\n",
    "\n",
    "### Load Full Mi:dm 2.0 Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bd287a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_id,\n",
    "    device_map=\"auto\",\n",
    "    attn_implementation=\"flash_attention_2\",\n",
    "    torch_dtype=torch.bfloat16\n",
    ")\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b58ba36",
   "metadata": {},
   "source": [
    "### Training Arguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b65212e",
   "metadata": {},
   "outputs": [],
   "source": [
    "args = TrainingArguments(\n",
    "    output_dir=\"save_dir\",\n",
    "    num_train_epochs=1,\n",
    "    per_device_train_batch_size=1,\n",
    "    gradient_accumulation_steps=1,\n",
    "    gradient_checkpointing=True,\n",
    "    logging_steps=10,\n",
    "    save_strategy=\"epoch\",\n",
    "    learning_rate=2e-5,\n",
    "    bf16=True,\n",
    "    max_grad_norm=1.0,\n",
    "    warmup_ratio=0.03,\n",
    "    lr_scheduler_type=\"constant\",\n",
    "    push_to_hub=False,\n",
    "    report_to=\"tensorboard\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2acb93e3",
   "metadata": {},
   "source": [
    "### Train with SFTTrainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36c453b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from trl import SFTTrainer\n",
    "\n",
    "trainer = SFTTrainer(\n",
    "    model=model,\n",
    "    args=args,\n",
    "    train_dataset=dataset,\n",
    "    processing_class=tokenizer\n",
    ")\n",
    "\n",
    "trainer.train()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "midm2.0",
   "language": "python",
   "name": "python3"
  },
  "language": "python",
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
